flink的状态是保存在内存中的，如何防止内存不爆，分布式，每个slot有独立的内存  
并行度调整后，flink会把原先状态数据打乱重新均匀分配  
容错性，会持久化状态  

flink的状态分类：  
托管状态，由flink管理的，直接调flink接口  
原始状态，自定义的，自己管理  

状态内容：  
值状态ValueState  
列表状态ListState  
映射状态MapState  
聚合状态AggregateState  

状态只针对当前的并行子任务里面有效  
p97-p101 很啰嗦，没有实例，有点水，根据讲义讲的  

## 实例

五种不同状态编程StateTest，较好  
统计每个用户的pv，PeriodicPvExample，较好  
列表状态全外联结， TwoStreamJoinExample，例子不太好，水过  
统计整10秒窗口，各个url点击次数，FakeWindowExample 较好  
统计每个人过去5次访问的平均时间戳，AverageTimestampExample， 较好  

## DataStream算子为啥不能直接聚合，而要先keyBy呢

本质上是状态是按key保存的

## TTL

p108 讲得不好  

## 三种算子状态

p109 纯讲解，不好  
ListState、UnionListState、BroadcastState  

UnionListState： 效率低，一般不用  
BroadcastState： 希望每个子任务都有一份相同状态  

## 算子状态

p110、p111 和容错结合起来的算子状态
10条一次性输出，发生错误会从checkpoint中恢复  BufferingSinkExample  

## 广播状态

所有算子状态都一样
应用场景：动态配置、动态规则  

广播状态例子BehaviorPatternDetectExample， 实 验做出来了，不理解，水过  

## 检查点

存储： 分布式文件系统  
检查点：某个时间点的一个快照

## 状态后端

哈希表状态后端HashMapStateBackend，状态放taskmanager的内存里， 适用于大状态、长窗口、大键值状态的作业    

内嵌RocksDB状态后端，EmbeddedRocksDBStateBackend，可以存放更多数据，是异步快照

flink中配置：  
state.backend: hashmap  
state.checkpoints.dir: 


## 故障恢复

前一个保存结点恢复，并重放数据  

按数据处理完之后的状态进行保存  

p115--p124 根据讲义讲检查点，没有例子，水过   

## 检查点算法

Flink使用了Chandy-Lamport算法的一种变体，被称为"异步分界线快照"算法，核心是两个原则：  
1、多上游任务向多个并行下游任务发送barrier时，需要广播出去  
2、当多个上游任务向同一个下游任务传递barrier时，需要在下游任务执行"分界线对齐"操作  

## 保存点

有计划的手动备份和恢复

## 状态一致性

状态恢复时，不会重复写入技术：  
幂等写入  
事务写入  